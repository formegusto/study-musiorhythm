{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b0409ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/formegusto/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf \n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "# 일관된 출력을 위해 유사난수 초기화\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# 한글출력\n",
    "# matplotlib.rc('font', family='AppleGothic')  # MacOS\n",
    "# matplotlib.rc('font', family='Malgun Gothic')  # Windows\n",
    "matplotlib.rc('font', family='NanumBarunGothic') # Linux\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "def plot_image(image, shape=[28, 28]):\n",
    "    plt.imshow(image.reshape(shape), cmap=\"Greys\", interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "def plot_multiple_images(images, n_rows, n_cols, pad=2):\n",
    "    images = images - images.min()  # 최소값을 0으로 만들어 패딩이 하얗게 보이도록 합니다.\n",
    "    w,h = images.shape[1:]\n",
    "    image = np.zeros(((w+pad)*n_rows+pad, (h+pad)*n_cols+pad))\n",
    "    for y in range(n_rows):\n",
    "        for x in range(n_cols):\n",
    "            image[(y*(h+pad)+pad):(y*(h+pad)+pad+h),(x*(w+pad)+pad):(x*(w+pad)+pad+w)] = images[y*n_cols+x]\n",
    "    plt.imshow(image, cmap=\"Greys\", interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch\n",
    "    \n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ed6ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 1000  # 희소 코딩 유닛\n",
    "n_outputs = n_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da22086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(p, q):\n",
    "    # 쿨백 라이블러 발산\n",
    "    return p * tf.log(p / q) + (1 - p) * tf.log((1 - p) / (1 - q))\n",
    "\n",
    "learning_rate = 0.01\n",
    "sparsity_target = 0.1\n",
    "sparsity_weight = 0.2\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_inputs])            # 책에는 없음\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.sigmoid) # 책에는 없음\n",
    "outputs = tf.layers.dense(hidden1, n_outputs)                     # 책에는 없음\n",
    "\n",
    "hidden1_mean = tf.reduce_mean(hidden1, axis=0) # 배치 평균\n",
    "sparsity_loss = tf.reduce_sum(kl_divergence(sparsity_target, hidden1_mean))\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X)) # MSE\n",
    "loss = reconstruction_loss + sparsity_weight * sparsity_loss\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80ec9fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28799d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 훈련 MSE: 0.06617325 \t희소 손실: 0.003382287 \t전체 손실: 0.06684971\n",
      "1 훈련 MSE: 0.063242674 \t희소 손실: 5.8615464e-05 \t전체 손실: 0.06325439\n",
      "2 훈련 MSE: 0.061897162 \t희소 손실: 0.00038104644 \t전체 손실: 0.06197337\n",
      "3 훈련 MSE: 0.06215215 \t희소 손실: 3.0237716e-05 \t전체 손실: 0.062158197\n",
      "4 훈련 MSE: 0.059958447 \t희소 손실: 0.0012078471 \t전체 손실: 0.060200017\n",
      "5 훈련 MSE: 0.05795762 \t희소 손실: 0.0014181416 \t전체 손실: 0.058241248\n",
      "6 훈련 MSE: 0.058964625 \t희소 손실: 0.00030663516 \t전체 손실: 0.05902595\n",
      "7 훈련 MSE: 0.05805256 \t희소 손실: 0.0007861671 \t전체 손실: 0.05820979\n",
      "8 훈련 MSE: 0.05846902 \t희소 손실: 6.5569766e-05 \t전체 손실: 0.058482133\n",
      "9 훈련 MSE: 0.05857562 \t희소 손실: 0.00033814833 \t전체 손실: 0.058643248\n",
      "10 훈련 MSE: 0.05838547 \t희소 손실: 6.2436855e-05 \t전체 손실: 0.058397956\n",
      "11 훈련 MSE: 0.058195334 \t희소 손실: 0.000335366 \t전체 손실: 0.058262408\n",
      "12 훈련 MSE: 0.05785378 \t희소 손실: 0.00026819902 \t전체 손실: 0.05790742\n",
      "13 훈련 MSE: 0.05748144 \t희소 손실: 0.00047850236 \t전체 손실: 0.05757714\n",
      "14 훈련 MSE: 0.057812005 \t희소 손실: 0.0006149863 \t전체 손실: 0.057935003\n",
      "15 훈련 MSE: 0.05774809 \t희소 손실: 2.44088e-05 \t전체 손실: 0.05775297\n",
      "16 훈련 MSE: 0.056204684 \t희소 손실: 0.0003432195 \t전체 손실: 0.056273326\n",
      "17 훈련 MSE: 0.058136705 \t희소 손실: 0.00019761396 \t전체 손실: 0.058176227\n",
      "18 훈련 MSE: 0.05705739 \t희소 손실: 0.0002504266 \t전체 손실: 0.05710748\n",
      "19 훈련 MSE: 0.05795932 \t희소 손실: 0.00067033106 \t전체 손실: 0.058093384\n",
      "20 훈련 MSE: 0.05645976 \t희소 손실: 0.00030059903 \t전체 손실: 0.056519877\n",
      "21 훈련 MSE: 0.056007687 \t희소 손실: 0.0008328967 \t전체 손실: 0.056174267\n",
      "22 훈련 MSE: 0.05666992 \t희소 손실: 1.9426996e-05 \t전체 손실: 0.056673806\n",
      "23 훈련 MSE: 0.05716626 \t희소 손실: 7.642759e-05 \t전체 손실: 0.057181545\n",
      "24 훈련 MSE: 0.05713801 \t희소 손실: 0.0002471076 \t전체 손실: 0.05718743\n",
      "25 훈련 MSE: 0.05657957 \t희소 손실: 0.0001664796 \t전체 손실: 0.056612868\n",
      "26 훈련 MSE: 0.056620605 \t희소 손실: 0.0007357225 \t전체 손실: 0.05676775\n",
      "27 훈련 MSE: 0.056129355 \t희소 손실: 0.0008146162 \t전체 손실: 0.056292277\n",
      "28 훈련 MSE: 0.057398424 \t희소 손실: 0.00065132044 \t전체 손실: 0.05752869\n",
      "29 훈련 MSE: 0.05756525 \t희소 손실: 3.6754125e-05 \t전체 손실: 0.0575726\n",
      "30 훈련 MSE: 0.05747454 \t희소 손실: 0.0004131915 \t전체 손실: 0.057557177\n",
      "31 훈련 MSE: 0.057426453 \t희소 손실: 0.00029294565 \t전체 손실: 0.05748504\n",
      "32 훈련 MSE: 0.0576326 \t희소 손실: 6.0189283e-05 \t전체 손실: 0.057644635\n",
      "33 훈련 MSE: 0.05581423 \t희소 손실: 0.00018066377 \t전체 손실: 0.05585036\n",
      "34 훈련 MSE: 0.057395607 \t희소 손실: 0.0006283687 \t전체 손실: 0.05752128\n",
      "35 훈련 MSE: 0.056023974 \t희소 손실: 0.00036037015 \t전체 손실: 0.056096047\n",
      "36 훈련 MSE: 0.056881107 \t희소 손실: 8.543627e-05 \t전체 손실: 0.056898195\n",
      "37 훈련 MSE: 0.056549165 \t희소 손실: 0.00015934656 \t전체 손실: 0.056581035\n",
      "38 훈련 MSE: 0.05581244 \t희소 손실: 6.5361382e-06 \t전체 손실: 0.05581375\n",
      "39 훈련 MSE: 0.056890108 \t희소 손실: 3.7759834e-05 \t전체 손실: 0.05689766\n",
      "40 훈련 MSE: 0.056171138 \t희소 손실: 0.00011129293 \t전체 손실: 0.056193396\n",
      "41 훈련 MSE: 0.056089517 \t희소 손실: 2.5123998e-05 \t전체 손실: 0.056094542\n",
      "42 훈련 MSE: 0.057060078 \t희소 손실: 0.00023075443 \t전체 손실: 0.05710623\n",
      "43 훈련 MSE: 0.05624415 \t희소 손실: 0.00025206385 \t전체 손실: 0.056294564\n",
      "44 훈련 MSE: 0.056900665 \t희소 손실: 8.2022045e-05 \t전체 손실: 0.05691707\n",
      "45 훈련 MSE: 0.05642475 \t희소 손실: 0.0011049304 \t전체 손실: 0.056645736\n",
      "46 훈련 MSE: 0.056818273 \t희소 손실: 8.798065e-05 \t전체 손실: 0.056835867\n",
      "47 훈련 MSE: 0.056780215 \t희소 손실: 1.4395628e-05 \t전체 손실: 0.056783095\n",
      "48 훈련 MSE: 0.055368736 \t희소 손실: 0.0005071532 \t전체 손실: 0.05547017\n",
      "49 훈련 MSE: 0.056557566 \t희소 손실: 3.7593185e-05 \t전체 손실: 0.056565084\n",
      "50 훈련 MSE: 0.05604804 \t희소 손실: 0.00049929647 \t전체 손실: 0.0561479\n",
      "51 훈련 MSE: 0.05639765 \t희소 손실: 9.166403e-05 \t전체 손실: 0.056415983\n",
      "52 훈련 MSE: 0.05694185 \t희소 손실: 0.00049415044 \t전체 손실: 0.057040676\n",
      "53 훈련 MSE: 0.056865316 \t희소 손실: 2.4143723e-05 \t전체 손실: 0.056870144\n",
      "54 훈련 MSE: 0.05651764 \t희소 손실: 1.36093e-05 \t전체 손실: 0.05652036\n",
      "55 훈련 MSE: 0.056117605 \t희소 손실: 2.9510848e-06 \t전체 손실: 0.056118194\n",
      "56 훈련 MSE: 0.056166254 \t희소 손실: 5.5366894e-05 \t전체 손실: 0.056177326\n",
      "57 훈련 MSE: 0.057265278 \t희소 손실: 0.0002154694 \t전체 손실: 0.057308372\n",
      "58 훈련 MSE: 0.0564886 \t희소 손실: 0.00070778513 \t전체 손실: 0.056630157\n",
      "59 훈련 MSE: 0.056104608 \t희소 손실: 8.59811e-05 \t전체 손실: 0.056121804\n",
      "60 훈련 MSE: 0.055841394 \t희소 손실: 0.00029483577 \t전체 손실: 0.05590036\n",
      "61 훈련 MSE: 0.056517284 \t희소 손실: 5.582563e-05 \t전체 손실: 0.05652845\n",
      "62 훈련 MSE: 0.057169195 \t희소 손실: 4.9787806e-05 \t전체 손실: 0.057179153\n",
      "63 훈련 MSE: 0.056400824 \t희소 손실: 5.9127924e-06 \t전체 손실: 0.056402005\n",
      "64 훈련 MSE: 0.05565001 \t희소 손실: 0.0002502522 \t전체 손실: 0.05570006\n",
      "65 훈련 MSE: 0.05649545 \t희소 손실: 5.3303665e-07 \t전체 손실: 0.05649556\n",
      "66 훈련 MSE: 0.05716054 \t희소 손실: 0.00013596407 \t전체 손실: 0.057187736\n",
      "67 훈련 MSE: 0.056600206 \t희소 손실: 3.7293416e-05 \t전체 손실: 0.056607664\n",
      "68 훈련 MSE: 0.056582518 \t희소 손실: 3.414415e-05 \t전체 손실: 0.056589346\n",
      "69 훈련 MSE: 0.05658592 \t희소 손실: 1.7757586e-05 \t전체 손실: 0.05658947\n",
      "70 훈련 MSE: 0.056908038 \t희소 손실: 3.5366393e-05 \t전체 손실: 0.05691511\n",
      "71 훈련 MSE: 0.0568044 \t희소 손실: 0.0003090715 \t전체 손실: 0.056866214\n",
      "72 훈련 MSE: 0.05655953 \t희소 손실: 2.0883628e-05 \t전체 손실: 0.056563705\n",
      "73 훈련 MSE: 0.055480145 \t희소 손실: 2.326e-05 \t전체 손실: 0.055484798\n",
      "74 훈련 MSE: 0.055925213 \t희소 손실: 4.0569692e-05 \t전체 손실: 0.055933326\n",
      "75 훈련 MSE: 0.057610933 \t희소 손실: 0.00337119 \t전체 손실: 0.05828517\n",
      "76 훈련 MSE: 0.055862922 \t희소 손실: 8.931442e-05 \t전체 손실: 0.055880785\n",
      "77 훈련 MSE: 0.055983298 \t희소 손실: 3.5619247e-05 \t전체 손실: 0.05599042\n",
      "78 훈련 MSE: 0.056394894 \t희소 손실: 4.1940686e-05 \t전체 손실: 0.056403283\n",
      "79 훈련 MSE: 0.05610798 \t희소 손실: 1.1989963e-05 \t전체 손실: 0.05611038\n",
      "80 훈련 MSE: 0.05733583 \t희소 손실: 2.375932e-05 \t전체 손실: 0.057340585\n",
      "81 훈련 MSE: 0.05632891 \t희소 손실: 3.9899023e-05 \t전체 손실: 0.05633689\n",
      "82 훈련 MSE: 0.056684148 \t희소 손실: 4.6680158e-05 \t전체 손실: 0.056693483\n",
      "83 훈련 MSE: 0.055816993 \t희소 손실: 1.2889272e-05 \t전체 손실: 0.05581957\n",
      "84 훈련 MSE: 0.055974964 \t희소 손실: 0.00013669732 \t전체 손실: 0.056002304\n",
      "85 훈련 MSE: 0.055720393 \t희소 손실: 1.4683901e-06 \t전체 손실: 0.055720687\n",
      "86 훈련 MSE: 0.05506953 \t희소 손실: 2.8799695e-06 \t전체 손실: 0.055070106\n",
      "87 훈련 MSE: 0.056172185 \t희소 손실: 2.130121e-05 \t전체 손실: 0.056176446\n",
      "88 훈련 MSE: 0.055877406 \t희소 손실: 5.4456643e-05 \t전체 손실: 0.0558883\n",
      "89 훈련 MSE: 0.05620759 \t희소 손실: 0.00019087599 \t전체 손실: 0.056245767\n",
      "90 훈련 MSE: 0.05547862 \t희소 손실: 9.921147e-06 \t전체 손실: 0.055480607\n",
      "91 훈련 MSE: 0.055558484 \t희소 손실: 7.133419e-05 \t전체 손실: 0.055572752\n",
      "92 훈련 MSE: 0.056239985 \t희소 손실: 1.7208047e-05 \t전체 손실: 0.056243427\n",
      "93 훈련 MSE: 0.056398354 \t희소 손실: 0.0013432279 \t전체 손실: 0.056667\n",
      "94 훈련 MSE: 0.056509007 \t희소 손실: 0.00016619288 \t전체 손실: 0.056542244\n",
      "95 훈련 MSE: 0.056096222 \t희소 손실: 1.551141e-05 \t전체 손실: 0.056099325\n",
      "96 훈련 MSE: 0.056334622 \t희소 손실: 0.00012059626 \t전체 손실: 0.05635874\n",
      "97 훈련 MSE: 0.05701416 \t희소 손실: 5.2475953e-06 \t전체 손실: 0.05701521\n",
      "98 훈련 MSE: 0.0560347 \t희소 손실: 6.975746e-05 \t전체 손실: 0.05604865\n",
      "99 훈련 MSE: 0.056686796 \t희소 손실: 1.8979335e-06 \t전체 손실: 0.056687176\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 1000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        n_batches = len(X_train) // batch_size\n",
    "        for iteration in range(n_batches):\n",
    "            print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            X_batch, y_batch = next(shuffle_batch(X_train, y_train, batch_size))\n",
    "            sess.run(training_op, feed_dict={X: X_batch})\n",
    "        reconstruction_loss_val, sparsity_loss_val, loss_val = sess.run([reconstruction_loss, sparsity_loss, loss], feed_dict={X: X_batch})\n",
    "        print(\"\\r{}\".format(epoch), \"훈련 MSE:\", reconstruction_loss_val, \"\\t희소 손실:\", sparsity_loss_val, \"\\t전체 손실:\", loss_val)\n",
    "        saver.save(sess, \"./my_model_sparse.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066bd57c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
